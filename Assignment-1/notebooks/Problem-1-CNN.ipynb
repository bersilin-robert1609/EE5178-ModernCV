{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import v2\n",
    "import torch.utils.data as dataloader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'cnn_vgg11_cifar10_pytorch'\n",
    "PROJECT_ENTITY = 'cs20b013-bersilin'\n",
    "\n",
    "\n",
    "LABELS = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "# VGG - 11 Arch\n",
    "ARCH = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(mean, std):\n",
    "    '''\n",
    "    Returns a transform to convert a CIFAR image to a tensor of type float32\n",
    "    '''\n",
    "    return v2.Compose([\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean, std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size: int, val_split: float = 0.2, shuffle: bool = True):\n",
    "    '''\n",
    "    Load the CIFAR-10 dataset\n",
    "    '''\n",
    "    train_data = datasets.CIFAR10(root=DATA_DIR, train=True, download=True)\n",
    "    test_data = datasets.CIFAR10(root=DATA_DIR, train=False, download=True)\n",
    "\n",
    "    mean = np.array(train_data.data).mean(axis=(0, 1, 2)) / 255\n",
    "    std = np.array(train_data.data).std(axis=(0, 1, 2)) / 255\n",
    "\n",
    "    transform = get_transform(mean, std)\n",
    "    train_data.transform = transform\n",
    "    test_data.transform = transform\n",
    "\n",
    "    train_size = int((1 - val_split) * len(train_data))\n",
    "    val_size = len(train_data) - train_size\n",
    "\n",
    "    train_data, val_data = dataloader.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "    train_loader = dataloader.DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n",
    "    val_loader = dataloader.DataLoader(val_data, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_loader = dataloader.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_data, test_data, train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_image(dataset: datasets.CIFAR10, index: int = None):\n",
    "    '''\n",
    "    Shows a random image from the dataset\n",
    "    '''\n",
    "    if index is None:\n",
    "        index = np.random.randint(0, len(dataset))\n",
    "    else:\n",
    "        index = index\n",
    "                \n",
    "    image, label = dataset[index]\n",
    "    \n",
    "    plot = plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"True Label: {LABELS[label]}\")\n",
    "    plt.show()\n",
    "\n",
    "    return plot, index, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(train_acc, val_acc):\n",
    "    '''\n",
    "    Plot the training and validation accuracies\n",
    "    '''\n",
    "    plot = plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture of the model\n",
    "\n",
    "class VGG_11(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(VGG_11, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv_layers = self.create_conv_layers(ARCH)\n",
    "\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, self.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "\n",
    "                layers += [\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                    nn.BatchNorm2d(x),\n",
    "                    nn.ReLU()\n",
    "                ]\n",
    "\n",
    "                in_channels = x\n",
    "            elif x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model: nn.Module, data_loader: dataloader.DataLoader, device: torch.device):\n",
    "    '''\n",
    "    Get the accuracy of the model on the data_loader\n",
    "    '''\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X)\n",
    "            _, predicted = torch.max(preds, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_labels(model: nn.Module, data_loader: dataloader.DataLoader, device: torch.device):\n",
    "    '''\n",
    "    Get the predicted labels of the model on the data_loader\n",
    "    '''\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X)\n",
    "            _, predicted = torch.max(preds, 1)\n",
    "            labels.append(predicted)\n",
    "\n",
    "    return torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "def train(configs, train_loader: dataloader.DataLoader, val_loader: dataloader.DataLoader, criterion: nn.CrossEntropyLoss,\n",
    "          optimizer: optim.Optimizer, model: nn.Module, device: torch.device):\n",
    "    '''\n",
    "    Train the model\n",
    "    '''\n",
    "    \n",
    "    print('Training the model...')\n",
    "    print('---------------------')\n",
    "\n",
    "    val_accuracies, train_accuracies = [], []\n",
    "\n",
    "    for epoch in range(configs['num_epochs']):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        total_iterations = len(train_loader)\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs) # Forward pass\n",
    "            loss = criterion(outputs, labels) # Calculate loss\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (i != total_iterations-1):\n",
    "                print(f'Epoch {epoch + 1}, Iteration {i + 1}/{total_iterations}, Loss: {loss.item()}', end='\\r')\n",
    "            else:\n",
    "                print(f'Epoch {epoch + 1}, Iteration {i + 1}/{total_iterations}, Loss: {loss.item()}')\n",
    "\n",
    "        print(f'Epoch {epoch + 1} done, Training Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "        # Validation loss\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Validation Loss: {val_loss / len(val_loader)}')\n",
    "\n",
    "        train_accuracy = get_accuracy(model, train_loader, device)\n",
    "        val_accuracy = get_accuracy(model, val_loader, device)\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Training Accuracy: {train_accuracy}, Validation Accuracy: {val_accuracy} \\n')\n",
    "\n",
    "        if configs['wandb_log']:\n",
    "            wandb.log({'Epoch:': epoch + 1,\n",
    "                       'Training Loss': running_loss / len(train_loader),\n",
    "                       'Validation Loss': val_loss / len(val_loader),\n",
    "                       'Training Accuracy': train_accuracy,\n",
    "                       'Validation Accuracy': val_accuracy})\n",
    "\n",
    "    print('Finished Training')\n",
    "    print('---------------------')\n",
    "    \n",
    "    return model, configs, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'Validation Accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'batch_size': {\n",
    "            'values': [50, 80, 100, 120, 150, 200]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.0005, 0.001, 0.003, 0.005, 0.007, 0.01, 0.03, 0.05]\n",
    "        },\n",
    "        'num_epochs': {\n",
    "            'values': [6, 8, 10, 12]\n",
    "        },\n",
    "        'momentum': {\n",
    "            'values': [0.87, 0.9, 0.93, 0.99]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=PROJECT_NAME, entity=PROJECT_ENTITY)\n",
    "\n",
    "def train_sweep():\n",
    "    run = wandb.init()\n",
    "\n",
    "    configs = {\n",
    "        'num_epochs': wandb.config.num_epochs,\n",
    "        'batch_size': wandb.config.batch_size,\n",
    "        'learning_rate': wandb.config.learning_rate,\n",
    "        'momentum': wandb.config.momentum,\n",
    "\n",
    "        'wandb_log': True\n",
    "    }\n",
    "\n",
    "    run.name = f\"lr={configs['learning_rate']}_bs={configs['batch_size']}_epochs={configs['num_epochs']}_r{np.random.randint(0, 1000)}\"\n",
    "\n",
    "    model = VGG_11(in_channels=3, num_classes=10).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=configs['learning_rate'], momentum=configs['momentum'])\n",
    "    \n",
    "    wandb.watch(model, criterion, log='all')\n",
    "\n",
    "    train_data, test_data, train_loader, val_loader, test_loader = get_dataloader(configs['batch_size'])\n",
    "\n",
    "    model, configs, train_accuracies, val_accuracies = train(configs, train_loader, val_loader, criterion, optimizer, model, device)\n",
    "\n",
    "    test_accuracy = get_accuracy(model, test_loader, device)\n",
    "    print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "    if configs['wandb_log']:\n",
    "        wandb.log({'Test Accuracy': test_accuracy})\n",
    "        wandb.log({'confusion_matrix': wandb.plot.confusion_matrix(probs=None,\n",
    "                                                                  y_true=test_data.targets,\n",
    "                                                                  preds=get_predicted_labels(model, test_loader, device).cpu().numpy(),\n",
    "                                                                  class_names=list(LABELS.values()))})\n",
    "        wandb.finish()\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train_sweep, count=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
